{"title":"Statistical inference","markdown":{"yaml":{"title":"Statistical inference","author":"Andrine Juvodden","date":"Dato","format":{"html":{"citation-style":"resources/apa.csl.txt","code-fold":true}},"bibliography":"resources/idr-4000-referanser.bib","output":"html_document","editor_options":{"chunk_output_type":"console"},"execute":{"echo":false,"warning":false,"message":false}},"headingText":"Oppgave 1","containsRefs":false,"markdown":"\n\n\n```{r, results='hide'}\n\nlibrary(tidyverse)\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\nsummary(m2)\n\n\n```\n\n#### Estimater\n\nEstimatene i regresjonsmodellene m1 og m2 representerer gjennomsnittene for hver gruppe. Her estimerer vi populasjonsgjennomsnittet basert på to forskjellige utvalgsstørrelser. Nøkkelen er at estimatet i begge modellene er gjennomsnittet av observerte verdier i utvalget. For m1 (utvalgsstørrelse 8) er estimert gjennomsnitt 1.840, noe som er litt annerledes enn det sanne populasjonsgjennomsnittet på 1.5. Utvalgsgjennomsnittet er en tilnærming av populasjonsgjennomsnittet, og nøyaktigheten avhenger av utvalgsstørrelsen. For m2 (utvalgsstørrelse 40) er estimert gjennomsnitt 1.5642, som er mye nærmere populasjonsgjennomsnittet på 1.5. Større utvalg reduserer vanligvis variasjonen i estimatet og gir en mer pålitelig tilnærming av populasjonsgjennomsnittet.\n\nThe estimates in the regression models `m1` and `m2` represent the sample means for each group. In this context, we're estimating the mean of a population based on two different sample sizes. The key point is that the estimate in both models is the average of the observed values in the sample.\n\nFor `m1` (sample size of 8), the estimated mean is 1.840, which is slightly different from the true population mean of 1.5. The sample mean is an approximation of the population mean, and the accuracy depends on sample size.\n\nFor `m2` (sample size of 40), the estimated mean is 1.5642, which is much closer to the population mean of 1.5. Larger sample sizes typically reduce the variability in the estimate, making it a more reliable approximation of the population mean.\n\n#### Standardfeil\n\nStandardfeilen (SE) er et mål på usikkerheten i estimatet. Den viser hvor mye gjennomsnittet fra et nytt tilfeldig utvalg forventes å avvike fra det vi har. For m1 er SE 1.251. En høy SE indikerer mer usikkerhet rundt estimatet på grunn av liten utvalgsstørrelse. For m2 er SE 0.4774, som er betydelig mindre enn for m1. Dette skyldes at et større utvalg reduserer variasjonen i estimatet, noe som gir et mer presist resultat.\n\n#### T-verdi og P-verdi\n\nFor m1 er t-verdien 1.47, beregnet som estimatet delt på SE. Dette indikerer hvor langt utvalgsgjennomsnittet er fra 0 målt i standardfeil.\n\nFor m2 er t-verdien 3.276, som er større på grunn av lavere SE og er et mer presist estimat i det større utvalget. En høyere t-verdi indikerer sterkere bevis for at gjennomsnittet er signifikant forskjellig fra 0.\n\nFor m1 er p-verdien 0.185, som betyr at det er 18.5 % sjanse for å observere en t-verdi så ekstrem som 1.47 hvis nullhypotesen (gjennomsnitt = 0) er sann. Siden dette er over den vanlige terskelen på 0.05, forkaster vi ikke nullhypotesen.\n\nFor m2 er p-verdien 0.00221, som er mye mindre og indikerer sterke bevis mot nullhypotesen. Dette antyder at det observerte gjennomsnittet (1.5642) er signifikant forskjellig fra 0.\n\n## Oppgave 2:\n\nDen primære forskjellen mellom de to modellene er utvalgsstørrelsene:\n\nLite utvalg (m1): Med bare 8 observasjoner er estimatet mindre presist, noe som fører til en høyere standardfeil og lavere t-verdi. Som et resultat forkaster vi ikke nullhypotesen, siden estimatet er for upresist til å kunne fastslå en forskjell fra 0 med sikkerhet.\n\nStort utvalg (m2): Med 40 observasjoner er estimatet mer presist, noe som gir lavere standardfeil, høyere t-verdi og lavere p-verdi. Den økte utvalgsstørrelsen gir større statistisk styrke, noe som gjør det lettere å oppdage en signifikant forskjell fra 0. Forskjellen i resultater mellom m1 og m2 skyldes altså forskjellen i utvalgsstørrelse. Det større utvalget gir mer pålitelige estimater og sterkere statistiske bevis.\n\n## Oppgave 3:\n\nI hypotesetesting bruker vi skyggeområdet i de nedre og øvre halene av t-fordelingen til å beregne p-verdien, som representerer sannsynligheten for å observere en t-verdi like ekstrem som den beregnet fra dataene, gitt at nullhypotesen er sann (gjennomsnitt = 0).\n\nFor tosidige tester ser vi på avvik fra 0 i begge retninger (positive og negative). Derfor beregner vi arealet under kurven i begge haler av fordelingen.\n\nSkyggeområdet tilsvarer andelen t-verdier som er like ekstreme eller mer ekstreme enn den observerte t-verdien. Hvis dette arealet (p-verdi) er lite, konkluderer vi med at slike ekstreme verdier sannsynligvis ikke oppstår tilfeldig, og vi kan kanskje forkaste nullhypotesen.\n\nFor m1 er skyggeområdet (p-verdi = 0.185) stort, noe som betyr at det er en høy sannsynlighet for å observere en t-verdi like ekstrem som 1.47. Derfor forkaster vi ikke nullhypotesen.\n\nFor m2 er skyggeområdet (p-verdi = 0.00221) lite, så vi forkaster nullhypotesen og konkluderer med at gjennomsnittet er signifikant forskjellig fra 0.\n\nVed å bruke både estimater og p-verdier fra m1 og m2 kan vi se hvordan utvalgsstørrelsen påvirker påliteligheten av statistiske slutninger.\n\n## Oppgave 4:\n\n```{r}\n\nlibrary(dplyr)\n\n\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n\n\nfor(i in 1:1000) {\n  \n\n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n\nresults <- bind_rows(results_8, results_40)\n\n\n\n\nsd_results <- results %>%\n  group_by(n) %>%\n  summarise(\n    sd_estimate = sd(estimate, na.rm = TRUE),\n    avg_se = mean(se, na.rm = TRUE)\n  )\n\nprint(sd_results)\n\n\n```\n\nStandardavviket til estimatene (sd_estimate) indikerer hvor mye estimatene varierer rundt gjennomsnittsestimatet for hver utvalgsstørrelse. Gjennomsnittlig standardfeil (avg_se) gir innsikt i variasjonen i selve estimatet. Hvis standardavviket til estimatene er nært gjennomsnittlig standardfeil, antyder det at estimatene er tett samlet rundt gjennomsnittet, og at SE er en pålitelig indikator på denne variasjonen.\n\n## Oppgave 5:\n\n```{r}\n\nlibrary(ggplot2)\n\n\nggplot(results, aes(x = pval, fill = factor(n))) + \n  geom_histogram(bins = 30, alpha = 0.7, position = \"identity\") +\n  labs(x = \"P-values\", y = \"Frequency\", fill = \"Sample Size\") +\n  theme_minimal() +\n  ggtitle(\"Histogram of P-values by Sample Size\") +\n  scale_fill_manual(values = c(\"blue\", \"orange\"), labels = c(\"Sample Size 8\", \"Sample Size 40\"))\n\n```\n\nTolkning\n\nHistogrammet lar oss visualisere fordelingen av p-verdier for hver utvalgsstørrelse. Et større utvalg resulterer vanligvis i en smalere p-verdi-fordeling, sentrert nærmere 0, noe som indikerer økt styrke til å påvise en effekt. Mindre utvalg kan derimot føre til en bredere fordeling med flere p-verdier som klynger seg nær 1.\n\n## Oppgave 6:\n\n```{r}\n\nalpha_level <- 0.05\n\n\nsignificant_results <- results %>%\n  group_by(n) %>%\n  summarise(significant_count = sum(pval < alpha_level, na.rm = TRUE))\n\nprint(significant_results)\n\n```\n\n## Oppgave 7:\n\n```{r}\n\nlibrary(pwr)\n\n\neffect_size <- 1.5 / 3\n\n\npower_results <- data.frame(\n  sample_size = c(8, 40),\n  power = c(\n    pwr.t.test(d = effect_size, n = 8, sig.level = alpha_level, type = \"one.sample\")$power,\n    pwr.t.test(d = effect_size, n = 40, sig.level = alpha_level, type = \"one.sample\")$power\n  )\n)\n\nprint(power_results)\n\n```\n\nForklaring av resultater\n\nStyrken til en test indikerer sannsynligheten for korrekt å forkaste nullhypotesen når den faktisk er feil. Høyere styrke betyr større sjanse for å oppdage en effekt dersom den finnes. Typisk gir større utvalgsstørrelser større styrke, noe som er indikert av de beregnede styrkene for de to utvalgsstørrelsene.\n\n## Oppgave 8:\n\n```{r}\n\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n\n\nfor(i in 1:1000) {\n  \n\n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n\nresults_null <- bind_rows(results_8, results_40)\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nggplot(results_null, aes(x = pval, fill = as.factor(n))) + \n  geom_histogram(position = \"dodge\", bins = 30, alpha = 0.7) +\n  labs(title = \"Histogram of P-values from Studies\", \n       x = \"P-value\", \n       y = \"Frequency\", \n       fill = \"Sample Size\") +\n  scale_fill_manual(values = c(\"blue\", \"orange\")) +\n  theme_minimal()\n\nfalse_positives_8 <- sum(results_null$pval[results_null$n == 8] < 0.05)\nfalse_positives_40 <- sum(results_null$pval[results_null$n == 40] < 0.05)\n\n\ncat(\"Number of false positives for sample size 8:\", false_positives_8, \"\\n\")\ncat(\"Number of false positives for sample size 40:\", false_positives_40, \"\\n\")\n\n\n```\n\nI hypotesetesting oppstår falske positive når vi feilaktig forkaster nullhypotesen. Ved et signifikansnivå på 0.05 forventer vi at omtrent 5 % av testene gir falske positive dersom nullhypotesen er sann.\n\nJeg kjørte 1000 simuleringer med utvalgsstørrelser på 8 og 40, med en populasjonsgjennomsnitt på 0 (nullhypotesen). Antall p-verdier mindre enn 0.05 representerer falske positive.\n\nUtvalgsstørrelse 8: 58 falske positive.\n\nUtvalgsstørrelse 40: 46 falske positive.\n\nResultatene viser at med et større utvalg reduseres antall falske positive noe, men ikke like mye som forventet. Selv om teorien antyder at større utvalg gir mer nøyaktige estimater og reduserer utvalgsvariasjonen, eliminerer de ikke falske positive helt. Forskjellen i falske positive mellom de to utvalgsstørrelsene (58 mot 46) er liten, men samsvarer fortsatt med den forventede raten for falske positive (rundt 5 %) over tid.\n","srcMarkdownNoYaml":"\n\n## Oppgave 1\n\n```{r, results='hide'}\n\nlibrary(tidyverse)\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\nsummary(m2)\n\n\n```\n\n#### Estimater\n\nEstimatene i regresjonsmodellene m1 og m2 representerer gjennomsnittene for hver gruppe. Her estimerer vi populasjonsgjennomsnittet basert på to forskjellige utvalgsstørrelser. Nøkkelen er at estimatet i begge modellene er gjennomsnittet av observerte verdier i utvalget. For m1 (utvalgsstørrelse 8) er estimert gjennomsnitt 1.840, noe som er litt annerledes enn det sanne populasjonsgjennomsnittet på 1.5. Utvalgsgjennomsnittet er en tilnærming av populasjonsgjennomsnittet, og nøyaktigheten avhenger av utvalgsstørrelsen. For m2 (utvalgsstørrelse 40) er estimert gjennomsnitt 1.5642, som er mye nærmere populasjonsgjennomsnittet på 1.5. Større utvalg reduserer vanligvis variasjonen i estimatet og gir en mer pålitelig tilnærming av populasjonsgjennomsnittet.\n\nThe estimates in the regression models `m1` and `m2` represent the sample means for each group. In this context, we're estimating the mean of a population based on two different sample sizes. The key point is that the estimate in both models is the average of the observed values in the sample.\n\nFor `m1` (sample size of 8), the estimated mean is 1.840, which is slightly different from the true population mean of 1.5. The sample mean is an approximation of the population mean, and the accuracy depends on sample size.\n\nFor `m2` (sample size of 40), the estimated mean is 1.5642, which is much closer to the population mean of 1.5. Larger sample sizes typically reduce the variability in the estimate, making it a more reliable approximation of the population mean.\n\n#### Standardfeil\n\nStandardfeilen (SE) er et mål på usikkerheten i estimatet. Den viser hvor mye gjennomsnittet fra et nytt tilfeldig utvalg forventes å avvike fra det vi har. For m1 er SE 1.251. En høy SE indikerer mer usikkerhet rundt estimatet på grunn av liten utvalgsstørrelse. For m2 er SE 0.4774, som er betydelig mindre enn for m1. Dette skyldes at et større utvalg reduserer variasjonen i estimatet, noe som gir et mer presist resultat.\n\n#### T-verdi og P-verdi\n\nFor m1 er t-verdien 1.47, beregnet som estimatet delt på SE. Dette indikerer hvor langt utvalgsgjennomsnittet er fra 0 målt i standardfeil.\n\nFor m2 er t-verdien 3.276, som er større på grunn av lavere SE og er et mer presist estimat i det større utvalget. En høyere t-verdi indikerer sterkere bevis for at gjennomsnittet er signifikant forskjellig fra 0.\n\nFor m1 er p-verdien 0.185, som betyr at det er 18.5 % sjanse for å observere en t-verdi så ekstrem som 1.47 hvis nullhypotesen (gjennomsnitt = 0) er sann. Siden dette er over den vanlige terskelen på 0.05, forkaster vi ikke nullhypotesen.\n\nFor m2 er p-verdien 0.00221, som er mye mindre og indikerer sterke bevis mot nullhypotesen. Dette antyder at det observerte gjennomsnittet (1.5642) er signifikant forskjellig fra 0.\n\n## Oppgave 2:\n\nDen primære forskjellen mellom de to modellene er utvalgsstørrelsene:\n\nLite utvalg (m1): Med bare 8 observasjoner er estimatet mindre presist, noe som fører til en høyere standardfeil og lavere t-verdi. Som et resultat forkaster vi ikke nullhypotesen, siden estimatet er for upresist til å kunne fastslå en forskjell fra 0 med sikkerhet.\n\nStort utvalg (m2): Med 40 observasjoner er estimatet mer presist, noe som gir lavere standardfeil, høyere t-verdi og lavere p-verdi. Den økte utvalgsstørrelsen gir større statistisk styrke, noe som gjør det lettere å oppdage en signifikant forskjell fra 0. Forskjellen i resultater mellom m1 og m2 skyldes altså forskjellen i utvalgsstørrelse. Det større utvalget gir mer pålitelige estimater og sterkere statistiske bevis.\n\n## Oppgave 3:\n\nI hypotesetesting bruker vi skyggeområdet i de nedre og øvre halene av t-fordelingen til å beregne p-verdien, som representerer sannsynligheten for å observere en t-verdi like ekstrem som den beregnet fra dataene, gitt at nullhypotesen er sann (gjennomsnitt = 0).\n\nFor tosidige tester ser vi på avvik fra 0 i begge retninger (positive og negative). Derfor beregner vi arealet under kurven i begge haler av fordelingen.\n\nSkyggeområdet tilsvarer andelen t-verdier som er like ekstreme eller mer ekstreme enn den observerte t-verdien. Hvis dette arealet (p-verdi) er lite, konkluderer vi med at slike ekstreme verdier sannsynligvis ikke oppstår tilfeldig, og vi kan kanskje forkaste nullhypotesen.\n\nFor m1 er skyggeområdet (p-verdi = 0.185) stort, noe som betyr at det er en høy sannsynlighet for å observere en t-verdi like ekstrem som 1.47. Derfor forkaster vi ikke nullhypotesen.\n\nFor m2 er skyggeområdet (p-verdi = 0.00221) lite, så vi forkaster nullhypotesen og konkluderer med at gjennomsnittet er signifikant forskjellig fra 0.\n\nVed å bruke både estimater og p-verdier fra m1 og m2 kan vi se hvordan utvalgsstørrelsen påvirker påliteligheten av statistiske slutninger.\n\n## Oppgave 4:\n\n```{r}\n\nlibrary(dplyr)\n\n\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n\n\nfor(i in 1:1000) {\n  \n\n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n\nresults <- bind_rows(results_8, results_40)\n\n\n\n\nsd_results <- results %>%\n  group_by(n) %>%\n  summarise(\n    sd_estimate = sd(estimate, na.rm = TRUE),\n    avg_se = mean(se, na.rm = TRUE)\n  )\n\nprint(sd_results)\n\n\n```\n\nStandardavviket til estimatene (sd_estimate) indikerer hvor mye estimatene varierer rundt gjennomsnittsestimatet for hver utvalgsstørrelse. Gjennomsnittlig standardfeil (avg_se) gir innsikt i variasjonen i selve estimatet. Hvis standardavviket til estimatene er nært gjennomsnittlig standardfeil, antyder det at estimatene er tett samlet rundt gjennomsnittet, og at SE er en pålitelig indikator på denne variasjonen.\n\n## Oppgave 5:\n\n```{r}\n\nlibrary(ggplot2)\n\n\nggplot(results, aes(x = pval, fill = factor(n))) + \n  geom_histogram(bins = 30, alpha = 0.7, position = \"identity\") +\n  labs(x = \"P-values\", y = \"Frequency\", fill = \"Sample Size\") +\n  theme_minimal() +\n  ggtitle(\"Histogram of P-values by Sample Size\") +\n  scale_fill_manual(values = c(\"blue\", \"orange\"), labels = c(\"Sample Size 8\", \"Sample Size 40\"))\n\n```\n\nTolkning\n\nHistogrammet lar oss visualisere fordelingen av p-verdier for hver utvalgsstørrelse. Et større utvalg resulterer vanligvis i en smalere p-verdi-fordeling, sentrert nærmere 0, noe som indikerer økt styrke til å påvise en effekt. Mindre utvalg kan derimot føre til en bredere fordeling med flere p-verdier som klynger seg nær 1.\n\n## Oppgave 6:\n\n```{r}\n\nalpha_level <- 0.05\n\n\nsignificant_results <- results %>%\n  group_by(n) %>%\n  summarise(significant_count = sum(pval < alpha_level, na.rm = TRUE))\n\nprint(significant_results)\n\n```\n\n## Oppgave 7:\n\n```{r}\n\nlibrary(pwr)\n\n\neffect_size <- 1.5 / 3\n\n\npower_results <- data.frame(\n  sample_size = c(8, 40),\n  power = c(\n    pwr.t.test(d = effect_size, n = 8, sig.level = alpha_level, type = \"one.sample\")$power,\n    pwr.t.test(d = effect_size, n = 40, sig.level = alpha_level, type = \"one.sample\")$power\n  )\n)\n\nprint(power_results)\n\n```\n\nForklaring av resultater\n\nStyrken til en test indikerer sannsynligheten for korrekt å forkaste nullhypotesen når den faktisk er feil. Høyere styrke betyr større sjanse for å oppdage en effekt dersom den finnes. Typisk gir større utvalgsstørrelser større styrke, noe som er indikert av de beregnede styrkene for de to utvalgsstørrelsene.\n\n## Oppgave 8:\n\n```{r}\n\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n\n\nfor(i in 1:1000) {\n  \n\n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n\nresults_null <- bind_rows(results_8, results_40)\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nggplot(results_null, aes(x = pval, fill = as.factor(n))) + \n  geom_histogram(position = \"dodge\", bins = 30, alpha = 0.7) +\n  labs(title = \"Histogram of P-values from Studies\", \n       x = \"P-value\", \n       y = \"Frequency\", \n       fill = \"Sample Size\") +\n  scale_fill_manual(values = c(\"blue\", \"orange\")) +\n  theme_minimal()\n\nfalse_positives_8 <- sum(results_null$pval[results_null$n == 8] < 0.05)\nfalse_positives_40 <- sum(results_null$pval[results_null$n == 40] < 0.05)\n\n\ncat(\"Number of false positives for sample size 8:\", false_positives_8, \"\\n\")\ncat(\"Number of false positives for sample size 40:\", false_positives_40, \"\\n\")\n\n\n```\n\nI hypotesetesting oppstår falske positive når vi feilaktig forkaster nullhypotesen. Ved et signifikansnivå på 0.05 forventer vi at omtrent 5 % av testene gir falske positive dersom nullhypotesen er sann.\n\nJeg kjørte 1000 simuleringer med utvalgsstørrelser på 8 og 40, med en populasjonsgjennomsnitt på 0 (nullhypotesen). Antall p-verdier mindre enn 0.05 representerer falske positive.\n\nUtvalgsstørrelse 8: 58 falske positive.\n\nUtvalgsstørrelse 40: 46 falske positive.\n\nResultatene viser at med et større utvalg reduseres antall falske positive noe, men ikke like mye som forventet. Selv om teorien antyder at større utvalg gir mer nøyaktige estimater og reduserer utvalgsvariasjonen, eliminerer de ikke falske positive helt. Forskjellen i falske positive mellom de to utvalgsstørrelsene (58 mot 46) er liten, men samsvarer fortsatt med den forventede raten for falske positive (rundt 5 %) over tid.\n"},"formats":{"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":"html_document","warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"03-statistical-inference.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"bibliography":["idr-4000-referanser.bib","resources/idr-4000-referanser.bib"],"title":"Statistical inference","author":"Andrine Juvodden","date":"Dato","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["pdf"]}