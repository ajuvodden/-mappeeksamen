---
title: "Statistical inference"
author: "Andrine Juvodden"
date: "Dato"
format:
  html:
    citation-style: resources/apa.csl.txt
    code-fold: true
bibliography: resources/idr-4000-referanser.bib
output: html_document
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  warning: false
  message: false
---

## Oppgave 1

```{r, results='hide'}

library(tidyverse)

set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)


samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

summary(m2)


```

#### Estimater

Estimatene i regresjonsmodellene m1 og m2 representerer gjennomsnittene for hver gruppe. Her estimerer vi populasjonsgjennomsnittet basert på to forskjellige utvalgsstørrelser. Nøkkelen er at estimatet i begge modellene er gjennomsnittet av observerte verdier i utvalget. For m1 (utvalgsstørrelse 8) er estimert gjennomsnitt 1.840, noe som er litt annerledes enn det sanne populasjonsgjennomsnittet på 1.5. Utvalgsgjennomsnittet er en tilnærming av populasjonsgjennomsnittet, og nøyaktigheten avhenger av utvalgsstørrelsen. For m2 (utvalgsstørrelse 40) er estimert gjennomsnitt 1.5642, som er mye nærmere populasjonsgjennomsnittet på 1.5. Større utvalg reduserer vanligvis variasjonen i estimatet og gir en mer pålitelig tilnærming av populasjonsgjennomsnittet.

The estimates in the regression models `m1` and `m2` represent the sample means for each group. In this context, we're estimating the mean of a population based on two different sample sizes. The key point is that the estimate in both models is the average of the observed values in the sample.

For `m1` (sample size of 8), the estimated mean is 1.840, which is slightly different from the true population mean of 1.5. The sample mean is an approximation of the population mean, and the accuracy depends on sample size.

For `m2` (sample size of 40), the estimated mean is 1.5642, which is much closer to the population mean of 1.5. Larger sample sizes typically reduce the variability in the estimate, making it a more reliable approximation of the population mean.

#### Standardfeil

Standardfeilen (SE) er et mål på usikkerheten i estimatet. Den viser hvor mye gjennomsnittet fra et nytt tilfeldig utvalg forventes å avvike fra det vi har. For m1 er SE 1.251. En høy SE indikerer mer usikkerhet rundt estimatet på grunn av liten utvalgsstørrelse. For m2 er SE 0.4774, som er betydelig mindre enn for m1. Dette skyldes at et større utvalg reduserer variasjonen i estimatet, noe som gir et mer presist resultat.

#### T-verdi og P-verdi

For m1 er t-verdien 1.47, beregnet som estimatet delt på SE. Dette indikerer hvor langt utvalgsgjennomsnittet er fra 0 målt i standardfeil.

For m2 er t-verdien 3.276, som er større på grunn av lavere SE og er et mer presist estimat i det større utvalget. En høyere t-verdi indikerer sterkere bevis for at gjennomsnittet er signifikant forskjellig fra 0.

For m1 er p-verdien 0.185, som betyr at det er 18.5 % sjanse for å observere en t-verdi så ekstrem som 1.47 hvis nullhypotesen (gjennomsnitt = 0) er sann. Siden dette er over den vanlige terskelen på 0.05, forkaster vi ikke nullhypotesen.

For m2 er p-verdien 0.00221, som er mye mindre og indikerer sterke bevis mot nullhypotesen. Dette antyder at det observerte gjennomsnittet (1.5642) er signifikant forskjellig fra 0.

## Oppgave 2:

Den primære forskjellen mellom de to modellene er utvalgsstørrelsene:

Lite utvalg (m1): Med bare 8 observasjoner er estimatet mindre presist, noe som fører til en høyere standardfeil og lavere t-verdi. Som et resultat forkaster vi ikke nullhypotesen, siden estimatet er for upresist til å kunne fastslå en forskjell fra 0 med sikkerhet.

Stort utvalg (m2): Med 40 observasjoner er estimatet mer presist, noe som gir lavere standardfeil, høyere t-verdi og lavere p-verdi. Den økte utvalgsstørrelsen gir større statistisk styrke, noe som gjør det lettere å oppdage en signifikant forskjell fra 0. Forskjellen i resultater mellom m1 og m2 skyldes altså forskjellen i utvalgsstørrelse. Det større utvalget gir mer pålitelige estimater og sterkere statistiske bevis.

## Oppgave 3:

I hypotesetesting bruker vi skyggeområdet i de nedre og øvre halene av t-fordelingen til å beregne p-verdien, som representerer sannsynligheten for å observere en t-verdi like ekstrem som den beregnet fra dataene, gitt at nullhypotesen er sann (gjennomsnitt = 0).

For tosidige tester ser vi på avvik fra 0 i begge retninger (positive og negative). Derfor beregner vi arealet under kurven i begge haler av fordelingen.

Skyggeområdet tilsvarer andelen t-verdier som er like ekstreme eller mer ekstreme enn den observerte t-verdien. Hvis dette arealet (p-verdi) er lite, konkluderer vi med at slike ekstreme verdier sannsynligvis ikke oppstår tilfeldig, og vi kan kanskje forkaste nullhypotesen.

For m1 er skyggeområdet (p-verdi = 0.185) stort, noe som betyr at det er en høy sannsynlighet for å observere en t-verdi like ekstrem som 1.47. Derfor forkaster vi ikke nullhypotesen.

For m2 er skyggeområdet (p-verdi = 0.00221) lite, så vi forkaster nullhypotesen og konkluderer med at gjennomsnittet er signifikant forskjellig fra 0.

Ved å bruke både estimater og p-verdier fra m1 og m2 kan vi se hvordan utvalgsstørrelsen påvirker påliteligheten av statistiske slutninger.

## Oppgave 4:

```{r}

library(dplyr)


results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)



for(i in 1:1000) {
  

  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  

  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}



results <- bind_rows(results_8, results_40)




sd_results <- results %>%
  group_by(n) %>%
  summarise(
    sd_estimate = sd(estimate, na.rm = TRUE),
    avg_se = mean(se, na.rm = TRUE)
  )

print(sd_results)


```

Standardavviket til estimatene (sd_estimate) indikerer hvor mye estimatene varierer rundt gjennomsnittsestimatet for hver utvalgsstørrelse. Gjennomsnittlig standardfeil (avg_se) gir innsikt i variasjonen i selve estimatet. Hvis standardavviket til estimatene er nært gjennomsnittlig standardfeil, antyder det at estimatene er tett samlet rundt gjennomsnittet, og at SE er en pålitelig indikator på denne variasjonen.

## Oppgave 5:

```{r}

library(ggplot2)


ggplot(results, aes(x = pval, fill = factor(n))) + 
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  labs(x = "P-values", y = "Frequency", fill = "Sample Size") +
  theme_minimal() +
  ggtitle("Histogram of P-values by Sample Size") +
  scale_fill_manual(values = c("blue", "orange"), labels = c("Sample Size 8", "Sample Size 40"))

```

Tolkning

Histogrammet lar oss visualisere fordelingen av p-verdier for hver utvalgsstørrelse. Et større utvalg resulterer vanligvis i en smalere p-verdi-fordeling, sentrert nærmere 0, noe som indikerer økt styrke til å påvise en effekt. Mindre utvalg kan derimot føre til en bredere fordeling med flere p-verdier som klynger seg nær 1.

## Oppgave 6:

```{r}

alpha_level <- 0.05


significant_results <- results %>%
  group_by(n) %>%
  summarise(significant_count = sum(pval < alpha_level, na.rm = TRUE))

print(significant_results)

```

## Oppgave 7:

```{r}

library(pwr)


effect_size <- 1.5 / 3


power_results <- data.frame(
  sample_size = c(8, 40),
  power = c(
    pwr.t.test(d = effect_size, n = 8, sig.level = alpha_level, type = "one.sample")$power,
    pwr.t.test(d = effect_size, n = 40, sig.level = alpha_level, type = "one.sample")$power
  )
)

print(power_results)

```

Forklaring av resultater

Styrken til en test indikerer sannsynligheten for korrekt å forkaste nullhypotesen når den faktisk er feil. Høyere styrke betyr større sjanse for å oppdage en effekt dersom den finnes. Typisk gir større utvalgsstørrelser større styrke, noe som er indikert av de beregnede styrkene for de to utvalgsstørrelsene.

## Oppgave 8:

```{r}

population <- rnorm(1000000, mean = 0, sd = 3)



results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)



for(i in 1:1000) {
  

  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}



results_null <- bind_rows(results_8, results_40)


library(dplyr)
library(ggplot2)

ggplot(results_null, aes(x = pval, fill = as.factor(n))) + 
  geom_histogram(position = "dodge", bins = 30, alpha = 0.7) +
  labs(title = "Histogram of P-values from Studies", 
       x = "P-value", 
       y = "Frequency", 
       fill = "Sample Size") +
  scale_fill_manual(values = c("blue", "orange")) +
  theme_minimal()

false_positives_8 <- sum(results_null$pval[results_null$n == 8] < 0.05)
false_positives_40 <- sum(results_null$pval[results_null$n == 40] < 0.05)


cat("Number of false positives for sample size 8:", false_positives_8, "\n")
cat("Number of false positives for sample size 40:", false_positives_40, "\n")


```

I hypotesetesting oppstår falske positive når vi feilaktig forkaster nullhypotesen. Ved et signifikansnivå på 0.05 forventer vi at omtrent 5 % av testene gir falske positive dersom nullhypotesen er sann.

Jeg kjørte 1000 simuleringer med utvalgsstørrelser på 8 og 40, med en populasjonsgjennomsnitt på 0 (nullhypotesen). Antall p-verdier mindre enn 0.05 representerer falske positive.

Utvalgsstørrelse 8: 58 falske positive.

Utvalgsstørrelse 40: 46 falske positive.

Resultatene viser at med et større utvalg reduseres antall falske positive noe, men ikke like mye som forventet. Selv om teorien antyder at større utvalg gir mer nøyaktige estimater og reduserer utvalgsvariasjonen, eliminerer de ikke falske positive helt. Forskjellen i falske positive mellom de to utvalgsstørrelsene (58 mot 46) er liten, men samsvarer fortsatt med den forventede raten for falske positive (rundt 5 %) over tid.
